{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"PyTorch_CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3-final"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-QYvwJB3Shud","colab_type":"text"},"source":["# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n","\n","Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n","Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n","\n","Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n","\n","Туториал по настройке Google Colab:  \n","https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n","(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FcXBeP1O7cnY","outputId":"5c9a3453-6e2c-4817-fbd7-b3fae940ebce","executionInfo":{"status":"ok","timestamp":1584881420113,"user_tz":-180,"elapsed":8884,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["# Intstall PyTorch and download data\n","!pip3 install torch torchvision\n","\n","!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-afwWw-Q85vD","colab":{}},"source":["from collections import namedtuple\n","import random\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import PIL\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.datasets as dset\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NNU-OD9O9ltP","colab":{}},"source":["device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-DwmEQAiShvb","colab_type":"text"},"source":["# Загружаем данные"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YAvkoRx-9FsP","colab":{}},"source":["# First, lets load the dataset\n","data_train = dset.SVHN('./', \n","                       transform=transforms.Compose([\n","                           transforms.ToTensor(),\n","                           transforms.Normalize(mean=[0.43,0.44,0.47],\n","                                               std=[0.20,0.20,0.20])                           \n","                       ])\n","                      )\n","data_test = dset.SVHN('./', split='test', transform=transforms.Compose([\n","                           transforms.ToTensor(),\n","                           transforms.Normalize(mean=[0.43,0.44,0.47],\n","                                               std=[0.20,0.20,0.20])                           \n","                       ]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLoVLcsiShvm","colab_type":"text"},"source":["Разделяем данные на training и validation.\n","\n","На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YRnr8CPg7Hli","colab":{}},"source":["batch_size = 64\n","\n","data_size = data_train.data.shape[0]\n","validation_split = .2\n","split = int(np.floor(validation_split * data_size))\n","indices = list(range(data_size))\n","np.random.shuffle(indices)\n","\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n","                                           sampler=train_sampler)\n","val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n","                                         sampler=val_sampler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LyYvt-T67PBG","colab":{}},"source":["# We'll use a special helper module to shape it into a flat tensor\n","class Flattener(nn.Module):\n","    def forward(self, x):\n","        batch_size, *_ = x.shape\n","        return x.view(batch_size, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BMjhC8ckShv0","colab_type":"text"},"source":["Создадим простейшую сеть с новыми слоями:  \n","Convolutional - `nn.Conv2d`  \n","MaxPool - `nn.MaxPool2d`"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w9SFVGZP7SQd","colab":{}},"source":["nn_model = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(4),\n","            nn.Conv2d(64, 64, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(4),    \n","            Flattener(),\n","            nn.Linear(64*2*2, 10),\n","          )\n","\n","nn_model.type(torch.cuda.FloatTensor)\n","nn_model.to(device)\n","\n","loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n","optimizer = optim.SGD(nn_model.parameters(), lr=1e-1, weight_decay=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7MG21k8Shv7","colab_type":"text"},"source":["Восстановите функцию `compute_accuracy` из прошлого задания.  \n","Единственное отличие в новом - она должна передать данные на GPU прежде чем прогонять через модель. Сделайте это так же, как это делает функция `train_model`"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2ek3KVQK7hJ6","outputId":"a4ba5ada-f143-4c6f-af70-0a3f0dd850d0","executionInfo":{"status":"ok","timestamp":1584885357111,"user_tz":-180,"elapsed":78473,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs,scheduler=None):    \n","    loss_history = []\n","    train_history = []\n","    val_history = []\n","    for epoch in range(num_epochs):\n","        model.train() # Enter train mode\n","        \n","        loss_accum = 0\n","        correct_samples = 0\n","        total_samples = 0\n","        for i_step, (x, y) in enumerate(train_loader):\n","          \n","            x_gpu = x.to(device)\n","            y_gpu = y.to(device)\n","            prediction = model(x_gpu)    \n","            loss_value = loss(prediction, y_gpu)\n","            optimizer.zero_grad()\n","            loss_value.backward()\n","            optimizer.step()\n","            \n","            _, indices = torch.max(prediction, 1)\n","            correct_samples += torch.sum(indices == y_gpu)\n","            total_samples += y.shape[0]\n","            \n","            loss_accum += loss_value\n","\n","        ave_loss = loss_accum / i_step\n","        train_accuracy = float(correct_samples) / total_samples\n","        val_accuracy = compute_accuracy(model, val_loader)\n","\n","        if scheduler != None:\n","          scheduler.step()\n","        loss_history.append(float(ave_loss))\n","        train_history.append(train_accuracy)\n","        val_history.append(val_accuracy)\n","        \n","        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n","        \n","    return loss_history, train_history, val_history\n","        \n","def compute_accuracy(model, loader):\n","    \"\"\"\n","    Computes accuracy on the dataset wrapped in a loader\n","    \n","    Returns: accuracy as a float value between 0 and 1\n","    \"\"\"\n","    model.eval() # Evaluation mode\n","    truth = 0.0\n","    n = 0\n","    for x, y  in loader:\n","      x_device = x.to(device)\n","      y_device = y.to(device)\n","      preds = model(x_device)\n","      truth += sum(preds.argmax(1) == y_device)\n","      n += y_device.shape[0]\n","    return truth / n\n","\n","loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6a-3a1ZFGEw_"},"source":["# Аугментация данных (Data augmentation)\n","\n","В работе с изображениями одним из особенно важных методов является аугментация данных - то есть, генерация дополнительных данных для тренировки на основе изначальных.   \n","Таким образом, мы получаем возможность \"увеличить\" набор данных для тренировки, что ведет к лучшей работе сети.\n","Важно, чтобы аугментированные данные были похожи на те, которые могут встретиться в реальной жизни, иначе польза от аугментаций уменьшается и может ухудшить работу сети.\n","\n","С PyTorch идут несколько таких алгоритмов, называемых `transforms`. Более подробно про них можно прочитать тут -\n","https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms\n","\n","Ниже мы используем следующие алгоритмы генерации:\n","- ColorJitter - случайное изменение цвета\n","- RandomHorizontalFlip - горизонтальное отражение с вероятностью 50%\n","- RandomVerticalFlip - вертикальное отражение с вероятностью 50%\n","- RandomRotation - случайный поворот"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jCWMUWmr7t5g","colab":{}},"source":["tfs = transforms.Compose([\n","    transforms.ColorJitter(hue=.50, saturation=.50),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomRotation(50, resample=PIL.Image.BILINEAR),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.43,0.44,0.47],\n","                       std=[0.20,0.20,0.20])                           \n","])\n","\n","# Create augmented train dataset\n","data_aug_train = dset.SVHN('./', \n","                       transform=tfs\n","                      )\n","\n","train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, \n","                                           sampler=train_sampler)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-jeLpOQShwM","colab_type":"text"},"source":["Визуализируем результаты агментации (вообще, смотреть на сгенерированные данные всегда очень полезно)."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YlJJEro1KZ45","outputId":"1156a954-8714-4e77-dd27-e54847c174e8","executionInfo":{"status":"ok","timestamp":1584885427255,"user_tz":-180,"elapsed":3688,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# TODO: Visualize some augmented images!\n","# hint: you can create new datasets and loaders to accomplish this\n","\n","# Based on the visualizations, should we keep all the augmentations?\n","\n","tfs = transforms.Compose([\n","    transforms.ColorJitter(hue=.20, saturation=.20),\n","    transforms.RandomHorizontalFlip(),\n","    # transforms.RandomVerticalFlip(),\n","    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n","])\n","\n","data_aug_vis = dset.SVHN('./', \n","                       transform=tfs\n","                      )\n","\n","plt.figure(figsize=(30, 3))\n","\n","for i, (x, y) in enumerate(data_aug_vis):\n","    if i == 10:\n","        break\n","    plt.subplot(1, 10, i+1)\n","    plt.grid(False)\n","    plt.imshow(x)\n","    plt.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"o2LrmsYHoguB"},"source":["Все ли агментации одинаково полезны на этом наборе данных? Могут ли быть среди них те, которые собьют модель с толку?\n","\n","Выберите из них только корректные"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"evro9ksXGs9u","colab":{}},"source":["# TODO: \n","tfs = transforms.Compose([\n","    transforms.ColorJitter(hue=.20, saturation=.20),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.43,0.44,0.47],\n","                       std=[0.20,0.20,0.20])                           \n","])\n","data_aug_train = dset.SVHN('./', \n","                       transform=tfs\n","                      )\n","# TODO create new instances of loaders with the augmentations you chose\n","train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, \n","                                           sampler=train_sampler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PeO6Zw0DHqPR","outputId":"69d977a1-542e-4efb-abcf-d69bf34f8f14","executionInfo":{"status":"ok","timestamp":1584885629503,"user_tz":-180,"elapsed":189978,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Finally, let's train with augmentations!\n","\n","# Note we shouldn't use augmentations on validation\n","\n","loss_history, train_history, val_history = train_model(nn_model, train_aug_loader, val_loader, loss, optimizer, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r0bcioK6JBDK"},"source":["# LeNet\n","Попробуем имплементировать классическую архитектуру сверточной нейронной сети, предложенную Яном ЛеКуном в 1998 году. В свое время она достигла впечатляющих результатов на MNIST, посмотрим как она справится с SVHN?\n","Она описана в статье [\"Gradient Based Learning Applied to Document Recognition\"](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), попробуйте прочитать ключевые части и имплементировать предложенную архитетуру на PyTorch.\n","\n","Реализовывать слои и функцию ошибки LeNet, которых нет в PyTorch, **не нужно** - просто возьмите их размеры и переведите в уже известные нам Convolutional, Pooling и Fully Connected layers.\n","\n","Если в статье не очень понятно, можно просто погуглить LeNet и разобраться в деталях :)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ieEzZUglJAUB","colab":{}},"source":["# TODO: Implement LeNet-like architecture for SVHN task\n","lenet_model = nn.Sequential(\n","            nn.Conv2d(3, 6, 5),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(6, 16, 5),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(16, 120, 5),\n","            nn.ReLU(inplace=True),\n","            Flattener(),\n","            nn.Linear(120, 84),\n","            nn.Linear(84, 10)\n","    \n","          )\n","\n","lenet_model.type(torch.cuda.FloatTensor)\n","lenet_model.to(device)\n","\n","loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n","optimizer = optim.SGD(lenet_model.parameters(), lr=1e-1, weight_decay=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WMmaPfdeKk9H","outputId":"08e4b46d-e593-432b-d85f-454e29bc8fde","executionInfo":{"status":"ok","timestamp":1584886036969,"user_tz":-180,"elapsed":371609,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# Let's train it!\n","loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u_O9qiYySvuj"},"source":["# Подбор гиперпараметров"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i6mhfdQ9K-N3","outputId":"21d09bda-e88f-4947-9779-cd791ea33bc4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1584910234322,"user_tz":-120,"elapsed":14430257,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}}},"source":["# The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n","# We also encourage you to try different optimizers as well\n","\n","Hyperparams = namedtuple(\"Hyperparams\", ['learning_rate', 'anneal_epochs', 'reg'])\n","RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n","\n","learning_rates = [1e0, 1e-1, 1e-2, 1e-3, 1e-4]\n","anneal_coeff = 0.2\n","anneal_epochs = [1, 5]\n","reg = [1e-3, 1e-4, 1e-5, 1e-7]\n","\n","batch_size = 64\n","epoch_num = 10\n","\n","# Record all the runs here\n","# Key should be Hyperparams and values should be RunResult\n","run_record = {} \n","\n","# Use grid search or random search and record all runs in run_record dictionnary \n","# Important: perform search in logarithmic space!\n","\n","# TODO: Your code here!\n","for i in range(len(learning_rates)):\n","  for j in range(len(anneal_epochs)):\n","    for k in range(len(reg)):\n","      params = [learning_rates[i], anneal_epochs[j], reg[k]]\n","      print(\"lr: \", params[0], \" anneal_epochs: \", params[1], \" reg: \", params[2])\n","      lenet_model = nn.Sequential(\n","                  nn.Conv2d(3, 6, 5),\n","                  nn.ReLU(inplace=True),\n","                  nn.MaxPool2d(2, stride=2),\n","                  nn.Conv2d(6, 16, 5),\n","                  nn.ReLU(inplace=True),\n","                  nn.MaxPool2d(2, stride=2),\n","                  nn.Conv2d(16, 120, 5),\n","                  nn.ReLU(inplace=True),\n","                  Flattener(),\n","                  nn.Linear(120, 84),\n","                  nn.Linear(84, 10)\n","          \n","                )\n","\n","      lenet_model.type(torch.cuda.FloatTensor)\n","      lenet_model.to(device)\n","\n","      loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n","      optimizer = optim.Adam(lenet_model.parameters(), lr=params[0], betas=(0.9, 0.999), eps=1e-7, weight_decay=params[2])\n","      scheduler = optim.lr_scheduler.StepLR(optimizer, params[1], anneal_coeff)\n","      loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, \n","                  loss, optimizer, epoch_num, scheduler)\n","      run_record[Hyperparams(*params)] = RunResult(lenet_model, train_history, val_history, val_history[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y6xExdw8JB1l","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a1dcb4be-e71c-41f9-8438-c99ae6869d69","executionInfo":{"status":"ok","timestamp":1584910254185,"user_tz":-120,"elapsed":638,"user":{"displayName":"Vladimir Romaniuk","photoUrl":"","userId":"07543973283968947068"}}},"source":["best_val_accuracy = None\n","best_hyperparams = None\n","best_run = None\n","\n","for hyperparams, run_result in run_record.items():\n","    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n","        best_val_accuracy = run_result.final_val_accuracy\n","        best_hyperparams = hyperparams\n","        best_run = run_result\n","        \n","print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LOmsR0uVgtgf"},"source":["# Свободное упражнение - догоним и перегоним LeNet!\n","\n","Попробуйте найти архитектуру и настройки тренировки, чтобы выступить лучше наших бейзлайнов.\n","\n","Что можно и нужно попробовать:\n","- BatchNormalization (для convolution layers он в PyTorch называется [batchnorm2d](https://pytorch.org/docs/stable/nn.html#batchnorm2d))\n","- Изменить количество слоев и их толщину\n","- Изменять количество эпох тренировки\n","- Попробовать и другие агментации"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tSVhD747icoc","colab":{}},"source":["params = [1e-1,4,1e-7]\n","epoch_num = 30\n","anneal_coeff = 0.6\n","print(\"lr: \", params[0], \" anneal_epochs: \", params[1], \" reg: \", params[2])\n","best_model = nn.Sequential(\n","            nn.Conv2d(3, 6, 5),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(6, 16, 5),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(16, 120, 5),\n","            nn.ReLU(inplace=True),\n","            Flattener(),\n","            nn.Linear(120, 84),\n","            nn.Linear(84, 10)\n","    \n","          )\n","\n","best_model.type(torch.cuda.FloatTensor)\n","best_model.to(device)\n","\n","loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n","optimizer = optim.SGD(best_model.parameters(), lr=params[0], weight_decay=params[2])\n","scheduler = optim.lr_scheduler.StepLR(optimizer, params[1], anneal_coeff)\n","loss_history, train_history, val_history = train_model(best_model, train_aug_loader, val_loader, \n","                  loss, optimizer, epoch_num, scheduler)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ubeKgBcnhx7N"},"source":["# Финальный аккорд - проверим лучшую модель на test set\n","\n","В качестве разнообразия - напишите код для прогона модели на test set вы.\n","\n","В результате вы должны натренировать модель, которая покажет более **90%** точности на test set.  \n","Как водится, лучший результат в группе получит дополнительные баллы!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EIqM1kdeh-hd","colab":{}},"source":["test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)\n","final_test_accuracy = compute_accuracy(best_model, test_loader)\n","print(\"Final test accuracy - \", final_test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BfH6qip6kVX_","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}